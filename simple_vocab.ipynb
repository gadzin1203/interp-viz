{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch as t\n",
    "from torch import nn\n",
    "import transformers\n",
    "from trl.gpt2 import GPT2HeadWithValueModel, respond_to_batch\n",
    "from trl.ppo import PPOTrainer\n",
    "from typing import Tuple, List, Dict\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "from minigpt_utils import get_minigpt, MiniGPT\n",
    "from days.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [f\"cuda:{i}\" for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer._add_tokens([\"[BEGIN]\", \"[END]\"])\n",
    "tokenizer.pad_token = \"[END]\"\n",
    "tokenizer.eos_token = \"[END]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'v_head.summary.bias', 'lm_head.weight', 'v_head.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gen_model = GPT2HeadWithValueModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_logits = {}\n",
    "for token in range(tokenizer.vocab_size):\n",
    "    sentence = t.tensor([[tokenizer.bos_token_id, token]], dtype=t.long)\n",
    "    logits = gen_model(sentence)[0]\n",
    "    solo_logits[token] = t.softmax(logits, dim=2)[0, 0, token].detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(solo_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt2_p_token_after_bos.txt\", 'w') as f:\n",
    "    json.dump(solo_logits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt2_p_token_after_bos.txt\") as f:\n",
    "    target = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = t.tensor([target_dict[str(k)] for k in range(tokenizer.vocab_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try training with restricted vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000 = t.topk(target, k=1000).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000_set = set(top1000.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(logits, allowed):\n",
    "    logits[:,~allowed] = -t.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, queries, allowed, txt_len=20, top_k=0, top_p=1.0):\n",
    "    \"\"\"Sample text from language model.\"\"\"\n",
    "    input_ids = queries\n",
    "    for i in range(txt_len):\n",
    "        # Get Logits\n",
    "        outputs = model(input_ids)\n",
    "        next_token_logits = outputs[0][:, -1, :] # start from next token\n",
    "        mask(next_token_logits, allowed) # remove verboten vocab\n",
    "        next_token_logits = transformers.top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
    "        # Sample\n",
    "        probs = t.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "        probs[t.isnan(probs).nonzero()] = 0\n",
    "        next_token = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "        input_ids = torch.cat([input_ids, next_token.unsqueeze(-1)], dim=-1)\n",
    "    return input_ids[:, -txt_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    gen_model,\n",
    "    ref_model,\n",
    "    ppo_config,\n",
    "    vocab,\n",
    "    reward_fn,\n",
    "    device,\n",
    "    gen_len:int = 20,\n",
    "    top_p:float = 1.0,\n",
    "    num_batches:int = 2,\n",
    "):\n",
    "    ppo_trainer = PPOTrainer(gen_model, ref_model, **ppo_config)\n",
    "\n",
    "    # encode a query\n",
    "    # query_txt = \"This morning I went to the \"\n",
    "    query_tensor = (t.tensor([tokenizer.bos_token_id], dtype=t.long, device=device)\n",
    "                    .unsqueeze(0)\n",
    "                    .repeat(ppo_config['batch_size'], 1))\n",
    "        \n",
    "    batch_info = []\n",
    "    allowed = t.isin(t.arange(tokenizer.vocab_size, device=device), vocab)\n",
    "    for batch in tqdm(range(num_batches)):\n",
    "        # get model response\n",
    "        with t.no_grad():\n",
    "            response_tensor = generate(gen_model, query_tensor, allowed, txt_len=gen_len, top_p=top_p)\n",
    "\n",
    "        reward = reward_fn(response_tensor)\n",
    "\n",
    "        # train model with ppo\n",
    "        train_stats = ppo_trainer.step(query_tensor, response_tensor, reward)\n",
    "        batch_info.append(train_stats)\n",
    "\n",
    "    return batch_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silly_reward(pos_tokens: t.Tensor): # b, seq_len -> b\n",
    "    return t.max(pos_tokens, dim=1).values/tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'v_head.summary.bias', 'lm_head.weight', 'v_head.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2HeadWithValueModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'v_head.summary.bias', 'lm_head.weight', 'v_head.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 32/32 [07:31<00:00, 14.10s/it]\n"
     ]
    }
   ],
   "source": [
    "########## This cell runs a single layer+head on a single GPU\n",
    "# Prompt is just the begin token\n",
    "device = DEVICES[3]\n",
    "ppo_config= {\n",
    "    \"batch_size\": 64,\n",
    "    \"forward_batch_size\": 8,\n",
    "    \"adap_kl_ctrl\": False,\n",
    "    \"init_kl_coef\": 0,\n",
    "}\n",
    "ref_model = GPT2HeadWithValueModel.from_pretrained(\"gpt2\").to(device)\n",
    "gen_model = GPT2HeadWithValueModel.from_pretrained(\"gpt2\").to(device)\n",
    "batch_info=train(gen_model, ref_model, ppo_config, top1000_v2.to(device), silly_reward, device, num_batches=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3375, 0.3375, 0.5903, 0.2079, 0.5903, 0.3375, 0.3982, 0.3495, 0.3375,\n",
       "        0.3375, 0.3375, 0.2079], device='cuda:3')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tensor = (t.tensor([tokenizer.bos_token_id], dtype=t.long, device=device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(12, 1))\n",
    "allowed = t.isin(t.arange(tokenizer.vocab_size, device=device), top1000.to(device))\n",
    "text = generate(gen_model, query_tensor, allowed, txt_len=22)\n",
    "silly_reward(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    6, 10449,   345, 10449,   368,   368,    65,   368,   385,    11,\n",
       "           290,   345, 16962,    13,  7120,   368,   385, 10161,  1671,   385,\n",
       "         10161,  1671],\n",
       "        [    6, 10449,   345,     6,   355, 16962,   385,     6, 13847,     6,\n",
       "         10161,  1671,   385, 10161,  1671,   385, 14055, 16962,   385, 16962,\n",
       "           385,     6],\n",
       "        [    6, 18546,   368,     6, 10449,    70,   368,    11,   318,   368,\n",
       "           338, 14055, 29668,   368,    33,    72,    25, 13847,     6, 10161,\n",
       "           368, 16962],\n",
       "        [    6, 10449,   345,     6,   705,   368,   628,   198,  1135,   368,\n",
       "           385,   261,   345,    59,   368,   368,    33,   385,   368,    65,\n",
       "           385,     6],\n",
       "        [    6, 10449,   345,     6,   262, 10161,   338, 16962,   368,    33,\n",
       "           368,   385,    11, 10161,   385,   261, 29668,   368,    65,   385,\n",
       "             6, 16962],\n",
       "        [    6, 10449,   345,   355,   340,   338,   705,   368,   290,   705,\n",
       "           368,     6,  8199,    72,   705, 16962,     6, 10161,    65, 14055,\n",
       "         16962,    13],\n",
       "        [    6, 10449,   345,     6,   284,   262,   705,   368,   338,   257,\n",
       "         20012,     6, 16962,   368,    65, 10449,   345,    13,   628,   198,\n",
       "          1135,   368],\n",
       "        [    6,    40,  1477,    67, 10449, 10449, 10449,    38,    77,  2257,\n",
       "         10161,    65,   368,   385, 14055,  8248, 16962,    13, 17563, 16962,\n",
       "            13,    38],\n",
       "        [    6, 14055,   368,   368,   385,     6,  7282, 16962,     6,    33,\n",
       "           368,   385, 14055,  1273,   368,   385, 13847,     6,    33,   368,\n",
       "           385,  8199],\n",
       "        [    6, 10449,   345,     6,   705,   368, 16962,     6, 13847,     6,\n",
       "         11484,    82,     6, 10161, 10161,  1671,   385,   261, 10161,    65,\n",
       "           385,   368],\n",
       "        [    6, 10449,   345,     6,   355, 16962,   368,    65,   368,    65,\n",
       "            13,  8021,   368,    11, 16962,   368,    65,   368,    65,   368,\n",
       "            65,   368],\n",
       "        [    6, 10449,   345,   368,   368,  1671,   385,   628,   198, 10161,\n",
       "          1671,   385,     6, 10161,  1671,   385,    12,   368,  1671,   368,\n",
       "          1671,   385]], device='cuda:3')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f801a163700>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([info['ppo/loss/policy'][0] for info in batch_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_all = t.ones(tokenizer.vocab_size).bool()\n",
    "text = generate(gen_model, query_tensor, allow_all, txt_len=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612, 11954,\n",
       "          2612,  2612,  2612, 11954,  2612,  2612, 11954,  2612, 11954,  2612,\n",
       "         11954,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612, 11954,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "         11954,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612, 11954,  2612,  2612,  2612, 11954,\n",
       "          2612, 11954,  2612,  2612,  2612,  2612,  2612,  2612, 11954,  2612,\n",
       "          2612, 11954],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612, 11954,  2612,  2612,  2612,  2612,  2612, 11954,\n",
       "          2612, 11954],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612, 11954,  2612,  2612,  2612, 11954,\n",
       "          2612, 11954],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612, 11954],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612,  2612, 11954,  2612,  2612, 11954,\n",
       "          2612,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612, 11954,  2612,\n",
       "          2612,  2612],\n",
       "        [    6,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612,  2612,  2612, 11954,  2612,  2612,  2612,  2612,  2612,  2612,\n",
       "          2612, 11954]], device='cuda:3')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12, device='cuda:3')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(t.isin(text, top1000_v2.to(device)).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing two measures of token_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"v2_tok_counts.json\") as f:\n",
    "    v2_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = t.tensor([v2_dict.get(str(k),0) for k in range(tokenizer.vocab_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000_v2 = t.topk(v2, k=1000).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"&'%\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([5,6,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnoprstuvwxyz{|}~\\n aheinreon theeratenitisanoresedingalar to of in andaslestrolyid Iet A is onimamadse that for\\'s it you with 1ch as (if 2ers \"em was at Theusand orabthun00el from--alloutThe\\'t01..ieone.\" -are,\"clsoint\\n\\n It 0 [ \\'newe).. This –com =manThIn000, —up |10—...//It :12exco5019WeER11the**WhlessThis /20 )IN30St\": #15appmeON +be…AT14sc16tosh1325AR18byIfButHeES17ANOR\",YouforofnotbrENAs2480ISmy4022ALThereAndForback60use–\".ASCh2329ED27AnITWhat26289933IC70200REOntrWhen45ACST35likeAlIDAMOTSo6475\",\"How21ShwwwThatToLE3844Cl3632=\"OS39340537PhBC48Ad665547ADTr084909USNoAtProAPThey65070204Re10003Con68basedExUnLe3167WithArOPOneAllAfternet5906SheSc58CH()88BI46Immore57</43•newEMBlWhilePlMynameNot42FLPS::NewIssee90NowGetBeBy41\\xadnoIMDonhttp54500IP98SACC>>THContSP5253BAHere51butSomewithQu8689NAAddSp2015SeIRAppTSTheseAdvertisementwhich72PRAccordingAbEn96FromHoweverclassUp\")UNRes2014LevelDeCLOurManImageMoreSEOfWhyDoColMrGoSpeDSYes2016MeInt\">NameComSSTRhttpsPleaseInd2017thatReadOrTASuDAMSthisPCJustLetWellOhyouAmModOverLastDesFirstPerTypeCanEvenEveryTrumpSCDrPhotoRepSeeABPostEXSince2013OtherActThenNotePePLSecDataAnotherGettyHisRecPrefromMayTePrTVRelMost2012AlthoughSub\\'\\'ManyYourAnyFollowDuring(\"CoSetDisBackCompDonaldCheMPIdEdFlSourceAmericanSteItemOnceDefJohnSmTwoTimeAlsoLikeMarViewRedvarPart2018NetOutArtAssNSListPeopleRegAttBecauseRefCA***ClickNeBOGuTextWhoStarTransDespiteRemBeforeAreWhereLookAboutStepGrlinkWillGLGameTodaySimFileStatePoliceMonTop·UnderKeyEventGAHerOffBrCRConsMinClassInter\\u200bElStillThoseThanksSHDCMarkMcCalRetCheckRelatedCOMGlOBPageJoCarBlackNewsDownloadNextParOnlyGeEmGoodColorUpdateBothObjectPresidentBarMenDateStartSenThankSwTOBookAvailableWorldCorCodeDecWatchaboutGRVideoHeynewsEachAhThoughTableTHERunYeahPlayDavidRightUseSlFreeFinallyLogWindowsLinkCurrentOKBRLegYetOpenMaxDemStoryDidShareBenGoogleSignDescriptionPHHighSystemHaveFacebookPaulMakePatBelSecondGeneralBlockWhiteNeverTakeCountInfoSuperWorkBEActionThreeReutersBreBigUsingAcHand×EndclickUserBestBitMediaWarAntMichaelStrFullMaybeMainSpecialVerPowerMagAngGodFireHarReturnGreatEarlierPerhapsGreenCostGenTomPressWhichAuthorHeadDelSpeakingWebDoesPortLineNEWIsraelUSACoreSpaceChapterCallPlayerMacNorthNoneSurPostedBoxFormerFollowingJackAmongRobSorryOnlinePassBuyLocalBlueTheirChinaLongWelcomeLifeHavingJamesLaSchArticleCitySouthSeveralTotalTimTLBasedSanMalUKWestThroughLightGivenNumberFourTerEvPublic/*CopyrightShowAlexEmailWhetherSometimesHelloSupportTeamKeepRealChrisProductKingTraBroLookingEnglishMicrosoftObamaHomeAppleNotesJulyAirNationalEveryoneMarch©WithoutSamRussiaOverallVeryOkayClintonWinRememberFindComeProjectExpCardLawWasUPDATEUnitedMissEditorCommonHiTurnWouldUpdatedDarkWashingtonEnterBYSelectAdditionalBillContactPlusCanadaHealthHouseHistoryPriceAmericaJonJoinSearchUntilBeingEditCNNWomenConfLoveDiOkSmallAnnBobInfLiveFinalADVERTISEMENTReportSepJeffTitleWaterPaySteveHasFoxSureJoeDisclaimerWantEverythingCommunityFiveMuchGeorgeLearnHillaryCyLeadEarlyItsHumanOriginalGettingSocialQuickAnyoneCurrentlyHotSixPreviousIndiaTexasWASHINGTONIntroductionInformationWowThinkHelpSummaryGlobalBitcoinEarthGunNeedGiveBallChineseStandardCreditCouldEverDetails«RecentlyHappyResearchImagineJournalPotBritishStayRepublicanKimRecentAttackYesterdayJusticeOverviewBreakingStatsEmbCLOSE<|endoftext|>'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(sorted(top1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&\\'%)*(+,-05.3/6:748=1<;9eL?2BDCEAGI[XJN]@R�PKHVTFUgYWOn\\\\jqk^_aMdu�ipt`m��>clr} whoxhwyv�Zoill�S����\"#��ɾ~���f��{he��� you�|Ӣ��z do�թ�s�������� comp\\u05f9��� wor\\x02Q����Ͷ�����\\u07ba\\x01� g��\\x00��an\\x11The�����\\x03\\x0c\\x05���ge�� tra����\\x16 there��ain�ort��etb\\ton�am\\x0e\\x07���\\x0fيia Scott� the�\\x08�\\x17\\x0b��\\x14 inher�\\x1c\\x1b��\\x06�\\x15� t��\\r�ۀ\\x10�ar a�\\x1e� St�al����\\x1d\\x13art\\x18 re ser S and reik N��ll nowld Aions complethir\\x19 Uemle�\\x04 Bowidredun (ubateuric� on I� f\\x7fif J__ 1� p will behch Tat--ac can l scop�ra�ormendol an at e�ospe F have yin because is n Leit Oorimies or conost� L\\'s\\x1f j we itag thisve 5du o de againstizeix His bentcimericpp m G thatot foreringregap$ccame dist disib In kn leumod wh ab14 of�rawn makeut shpl don withompt our not as byingft Theast be01\\nour 2 fromings se w� pl alel allide st onlyideo�antithokongvern comould wereersich toighul becseayallyas\\x1a ne teab thoseest�ackaryntewkereeatesiveomeoselic wieldedimeInans unall M off itsentsrom r man agesob enoll\\x12 th� K car preav alsoore ifity \" piece C hisailless v millionckedine oneess didri somevery rockade her yourice E resment resultigqu more are whe00 look but\\'reated whichachax ablever full hereiz like - procludout�ous work tr partianualtt sa entbsightationusvelmed Thresordven longinceust13ifiedversand ro R otherindfter meiting sp firstract distectitionable hasike useens cre significantted u righten Wure themontroughountstclound per charff accish). person whatarkitiesollowency downhingonsks everyard inst... imrouwe finatch said twction followingits functionog indINso foundhed helpndberudreatove 4 filoy justryiv �ite studations kific ex They information upoad clakiedawists h last art even bet 19 THersonco sm..ics bl asslectossram ch app beenoh near----xtookionmerroundauseweenicitordingilcomced get where attph over co mom.,selperinkiver Bear 3== out than wantional Y could Ar lightou fl kind Qles She $ c refash about + add quull 0 theirghialaking Vgetiffie pass any\\'tarnays howenerors needrit Cldayold regterield callood |anghip playnderides//assintstand haginoryact hadainedov 6 Suther feel produ two transotoany po say This ball 21lyium 100 after000ance patces different dec cont count inter Sh goalityiseake Fr 201 peoplehes encough know,ating mostother threeek myair own challiet--------urityct heather year governaining doesex But until thency....ometutionowerysearories You AllWe subcessuchund day when exper grockup alongildrow spe Zgg triiredator galaxyitle Northderue201cing rem 20ounuedce cour was diffident increau short effology -- num mil ar see17ERger ide rel throughave 16 Howicesublic obtern Tr sometgo 7 imp bu\\'ll 14ecuss posants incvesWh sl affuringement fe ph Se — postetsell thing repalth House P It Aug— try way.book ev would cho barressraphformation Sp teamashingself act while warace Newpsborerestump Mc45 tooondense Nationalland 8 years exp80ting bestipruileef report ed perform goodowers Ministerments'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(top1000_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\')+,-./012345679:<=>?@CDFGHKLOPQUWX_bdefghjlmnquwxy�������������������������������������\\x02\\x06\\x12\\x15\\x16\\x1b\\x1c\\x1d\\x1e ������ ton theenesingar m ofic th re g I isimamay for u asers W r Fulromess Eort this O pl dorou jffions K theirber had,\"au wouldereite resailough than part kn newentsove prearkamp playhingject see fl Unoss Reific 10 reg veryotheroth==uringativeerson endful acself min—alk here world'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(t.isin(top1000,top1000_v2).nonzero().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t.isin(top1000,top1000_v2).nonzero().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
